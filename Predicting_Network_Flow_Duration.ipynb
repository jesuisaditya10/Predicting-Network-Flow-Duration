{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpGHovVGB64/ZAX7vnhvN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesuisaditya10/Predicting-Network-Flow-Duration/blob/main/Predicting_Network_Flow_Duration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "from datetime import datetime\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# --- Function Definitions ---\n",
        "\n",
        "def load_and_validate_data(file_path):\n",
        "    \"\"\"Load the dataset from a CSV file and validate required columns.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(\"Data loaded successfully!\")\n",
        "        print(f\"Dataset shape: {df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading the CSV file: {e}\")\n",
        "        raise\n",
        "\n",
        "    required_columns = [\n",
        "        'Flow.ID', 'Source.IP', 'Source.Port', 'Destination.IP',\n",
        "        'Destination.Port', 'Protocol', 'Timestamp', 'Flow.Duration',\n",
        "        'Total.Fwd.Packets', 'Total.Backward.Packets'\n",
        "    ]\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(\"Error: The CSV file does not contain all required columns.\")\n",
        "        print(f\"Missing columns: {missing_columns}\")\n",
        "        raise ValueError(\"Missing required columns\")\n",
        "    return df\n",
        "\n",
        "def explore_data(df):\n",
        "    \"\"\"Generate summary statistics and visualizations for data exploration.\"\"\"\n",
        "    print(\"\\n--- Data Exploration ---\")\n",
        "    print(df.describe())\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(df['Flow.Duration'], kde=True)\n",
        "    plt.title('Distribution of Flow Duration')\n",
        "    plt.xlabel('Flow Duration')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.savefig('flow_duration_distribution.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    corr = numeric_df.corr()\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.savefig('correlation_heatmap.png')\n",
        "    plt.close()\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocess the dataset: validate data types, handle outliers, and engineer features.\"\"\"\n",
        "    numeric_columns = ['Source.Port', 'Destination.Port', 'Protocol', 'Flow.Duration', 'Total.Fwd.Packets', 'Total.Backward.Packets']\n",
        "    for col in numeric_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        if df[col].isna().any():\n",
        "            print(f\"Warning: Column '{col}' contains non-numeric values. Rows with invalid values will be dropped.\")\n",
        "    df = df.dropna(subset=numeric_columns)\n",
        "\n",
        "    Q1 = df['Flow.Duration'].quantile(0.25)\n",
        "    Q3 = df['Flow.Duration'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df['Flow.Duration'] < lower_bound) | (df['Flow.Duration'] > upper_bound)]\n",
        "    if not outliers.empty:\n",
        "        print(f\"Detected {len(outliers)} outliers in Flow.Duration. Removing them...\")\n",
        "        df = df[(df['Flow.Duration'] >= lower_bound) & (df['Flow.Duration'] <= upper_bound)]\n",
        "\n",
        "    def ip_to_numeric(ip):\n",
        "        try:\n",
        "            parts = str(ip).split('.')\n",
        "            if len(parts) != 4:\n",
        "                raise ValueError(\"Invalid IP format\")\n",
        "            return int(parts[0]) * (256**3) + int(parts[1]) * (256**2) + int(parts[2]) * 256 + int(parts[3])\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    df['Source.IP.Num'] = df['Source.IP'].apply(ip_to_numeric)\n",
        "    df['Destination.IP.Num'] = df['Destination.IP'].apply(ip_to_numeric)\n",
        "\n",
        "    possible_formats = ['%d/%m/%Y %H:%M:%S', '%Y-%m-%d %H:%M:%S', '%m/%d/%Y %H:%M:%S']\n",
        "    timestamp_parsed = False\n",
        "    for fmt in possible_formats:\n",
        "        try:\n",
        "            df['Timestamp'] = pd.to_datetime(df['Timestamp'], format=fmt)\n",
        "            timestamp_parsed = True\n",
        "            break\n",
        "        except ValueError:\n",
        "            continue\n",
        "    if not timestamp_parsed:\n",
        "        print(\"Error: Unable to parse Timestamp column.\")\n",
        "        raise ValueError(\"Invalid Timestamp format\")\n",
        "\n",
        "    df['Hour'] = df['Timestamp'].dt.hour\n",
        "    df['Minute'] = df['Timestamp'].dt.minute\n",
        "    df['Second'] = df['Timestamp'].dt.second\n",
        "\n",
        "    df['Total.Packets'] = df['Total.Fwd.Packets'] + df['Total.Backward.Packets']\n",
        "    df['Packet.Ratio'] = df['Total.Fwd.Packets'] / (df['Total.Backward.Packets'] + 1e-5)\n",
        "    df['Duration.Per.Packet'] = df['Flow.Duration'] / (df['Total.Packets'] + 1e-5)\n",
        "\n",
        "    df = df.drop(['Flow.ID', 'Source.IP', 'Destination.IP', 'Timestamp'], axis=1)\n",
        "    return df\n",
        "\n",
        "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name, scaled=False):\n",
        "    \"\"\"Train a model, evaluate it, and return performance metrics.\"\"\"\n",
        "    if isinstance(model, GridSearchCV):\n",
        "        model.fit(X_train, y_train)\n",
        "        best_model = model.best_estimator_\n",
        "        print(f\"Best parameters for {model_name}: {model.best_params_}\")\n",
        "    else:\n",
        "        best_model = model\n",
        "        best_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    cv_scores = cross_val_score(best_model, X_train if not scaled else scaler.transform(X_train), y_train, cv=5, scoring='r2')\n",
        "    cv_mean = cv_scores.mean()\n",
        "\n",
        "    print(f\"\\n--- {model_name} ---\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"R-squared Score: {r2:.2f}\")\n",
        "    print(f\"Cross-Validation R-squared: {cv_mean:.2f}\")\n",
        "\n",
        "    return y_pred, {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'CV_R2': cv_mean}, best_model\n",
        "\n",
        "def plot_actual_vs_predicted(y_test, predictions, model_names):\n",
        "    \"\"\"Plot actual vs predicted values for each model.\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for y_pred, model_name in zip(predictions, model_names):\n",
        "        plt.scatter(y_test, y_pred, label=model_name, alpha=0.6)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "    plt.xlabel('Actual Flow Duration')\n",
        "    plt.ylabel('Predicted Flow Duration')\n",
        "    plt.title('Actual vs Predicted Flow Duration')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('actual_vs_predicted.png')\n",
        "    plt.close()\n",
        "\n",
        "def plot_feature_importance(model, model_name, feature_names):\n",
        "    \"\"\"Plot feature importance for tree-based models.\"\"\"\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(range(len(importances)), importances[indices], align='center')\n",
        "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
        "        plt.title(f'Feature Importance - {model_name}')\n",
        "        plt.xlabel('Features')\n",
        "        plt.ylabel('Importance')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'feature_importance_{model_name.lower().replace(\" \", \"_\")}.png')\n",
        "        plt.close()\n",
        "\n",
        "def plot_model_comparison(metrics_dict):\n",
        "    \"\"\"Plot a comparison of model performance metrics.\"\"\"\n",
        "    metrics_df = pd.DataFrame(metrics_dict).T\n",
        "    metrics_df.plot(kind='bar', figsize=(12, 8))\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Model')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Metrics')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "file_path = '/content/Network_rate_data.csv'\n",
        "df = load_and_validate_data(file_path)\n",
        "explore_data(df)\n",
        "\n",
        "df = preprocess_data(df)\n",
        "\n",
        "X = df.drop('Flow.Duration', axis=1)\n",
        "y = df['Flow.Duration']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "rf_params = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
        "rf_model = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=5, scoring='r2')\n",
        "xgb_params = {'n_estimators': [100, 200], 'max_depth': [3, 5, 7]}\n",
        "xgb_model = GridSearchCV(xgb.XGBRegressor(random_state=42, objective='reg:squarederror'), xgb_params, cv=5, scoring='r2')\n",
        "svr_model = GridSearchCV(SVR(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}, cv=5, scoring='r2')\n",
        "\n",
        "models = [\n",
        "    (lr_model, \"Linear Regression\", True),\n",
        "    (rf_model, \"Random Forest\", False),\n",
        "    (xgb_model, \"XGBoost\", True),\n",
        "    (svr_model, \"Support Vector Regressor\", True)\n",
        "]\n",
        "\n",
        "predictions = []\n",
        "metrics_dict = {}\n",
        "best_models = {}\n",
        "for model, name, scaled in models:\n",
        "    X_t = X_train_scaled if scaled else X_train\n",
        "    X_te = X_test_scaled if scaled else X_test\n",
        "    y_pred, metrics, best_model = train_and_evaluate_model(model, X_t, X_te, y_train, y_test, name, scaled)\n",
        "    predictions.append(y_pred)\n",
        "    metrics_dict[name] = metrics\n",
        "    best_models[name] = best_model\n",
        "\n",
        "    if name in [\"Random Forest\", \"XGBoost\"]:\n",
        "        plot_feature_importance(best_model, name, X.columns)\n",
        "\n",
        "plot_actual_vs_predicted(y_test, predictions, [name for _, name, _ in models])\n",
        "plot_model_comparison(metrics_dict)\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_dict).T\n",
        "metrics_df.to_csv('model_metrics.csv')\n",
        "\n",
        "best_model = max(metrics_dict.items(), key=lambda x: x[1]['R2'])\n",
        "best_model_name = best_model[0]\n",
        "best_model_instance = best_models[best_model_name]\n",
        "print(f\"\\nBest Model (based on R-squared): {best_model_name}\")\n",
        "\n",
        "scaled = any(name == best_model_name and scaled for _, name, scaled in models)\n",
        "sample = (X_test_scaled[-1] if scaled else X_test.iloc[-1].values).reshape(1, -1)\n",
        "predicted_duration = best_model_instance.predict(sample)\n",
        "print(f\"Predicted Flow Duration for the last test sample: {predicted_duration[0]:.2f}\")\n",
        "\n",
        "print(\"\\n--- Summary of Findings ---\")\n",
        "print(f\"The best-performing model was {best_model_name} with an R-squared of {metrics_dict[best_model_name]['R2']:.2f}.\")\n",
        "print(\"Key findings:\")\n",
        "print(\"- Random Forest and XGBoost generally outperformed Linear Regression and SVR.\")\n",
        "print(\"- Feature importance plots highlight key predictors like Total.Fwd.Packets and Protocol.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK6Ayx9WxEgc",
        "outputId": "69ae4760-e450-41b9-befb-6b1161f0c8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully!\n",
            "Dataset shape: (1500, 10)\n",
            "\n",
            "--- Data Exploration ---\n",
            "        Source.Port  Destination.Port     Protocol  Flow.Duration  \\\n",
            "count   1500.000000       1500.000000  1500.000000     1500.00000   \n",
            "mean   33215.566000       4666.183333    11.500000     4174.94000   \n",
            "std    18774.521131      12602.944308     5.501834     2806.24163   \n",
            "min     1041.000000         21.000000     6.000000      -82.00000   \n",
            "25%    16409.500000         22.000000     6.000000     1951.50000   \n",
            "50%    33594.500000         53.000000    11.500000     3464.00000   \n",
            "75%    49425.250000        443.000000    17.000000     5741.50000   \n",
            "max    65501.000000      64536.000000    17.000000    14618.00000   \n",
            "\n",
            "       Total.Fwd.Packets  Total.Backward.Packets  \n",
            "count        1500.000000             1500.000000  \n",
            "mean           76.363333               50.160667  \n",
            "std            43.347203               28.827826  \n",
            "min             1.000000                1.000000  \n",
            "25%            39.000000               24.000000  \n",
            "50%            77.000000               51.000000  \n",
            "75%           115.000000               75.000000  \n",
            "max           150.000000              100.000000  \n",
            "Detected 26 outliers in Flow.Duration. Removing them...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Regression ---\n",
            "Mean Squared Error (MSE): 699769.68\n",
            "Root Mean Squared Error (RMSE): 836.52\n",
            "Mean Absolute Error (MAE): 616.83\n",
            "R-squared Score: 0.91\n",
            "Cross-Validation R-squared: 0.90\n",
            "Best parameters for Random Forest: {'max_depth': 10, 'n_estimators': 200}\n",
            "\n",
            "--- Random Forest ---\n",
            "Mean Squared Error (MSE): 66902.13\n",
            "Root Mean Squared Error (RMSE): 258.65\n",
            "Mean Absolute Error (MAE): 138.32\n",
            "R-squared Score: 0.99\n",
            "Cross-Validation R-squared: 0.99\n",
            "Best parameters for XGBoost: {'max_depth': 5, 'n_estimators': 200}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost ---\n",
            "Mean Squared Error (MSE): 40489.67\n",
            "Root Mean Squared Error (RMSE): 201.22\n",
            "Mean Absolute Error (MAE): 138.59\n",
            "R-squared Score: 0.99\n",
            "Cross-Validation R-squared: 0.99\n",
            "Best parameters for Support Vector Regressor: {'C': 10, 'kernel': 'linear'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Support Vector Regressor ---\n",
            "Mean Squared Error (MSE): 792991.42\n",
            "Root Mean Squared Error (RMSE): 890.50\n",
            "Mean Absolute Error (MAE): 623.89\n",
            "R-squared Score: 0.90\n",
            "Cross-Validation R-squared: 0.02\n",
            "\n",
            "Best Model (based on R-squared): XGBoost\n",
            "Predicted Flow Duration for the last test sample: 3240.51\n",
            "\n",
            "--- Summary of Findings ---\n",
            "The best-performing model was XGBoost with an R-squared of 0.99.\n",
            "Key findings:\n",
            "- Random Forest and XGBoost generally outperformed Linear Regression and SVR.\n",
            "- Feature importance plots highlight key predictors like Total.Fwd.Packets and Protocol.\n"
          ]
        }
      ]
    }
  ]
}